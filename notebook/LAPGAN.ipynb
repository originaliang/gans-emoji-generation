{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H-tfUO2IQIRJ",
    "outputId": "04ba85cc-9636-463d-8a6f-b64177c1d8d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "def gen_noise(n_instance, n_dim):\n",
    "    return torch.Tensor(np.random.uniform(low=-1.0, high=1.0, size=(n_instance, n_dim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IcZL0UJg1INI"
   },
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "# parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "# parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "# parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "# parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "# parser.add_argument(\"--latent_dim\", type=int, default=62, help=\"dimensionality of the latent space\")\n",
    "# parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\n",
    "# parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "# parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\n",
    "# opt = parser.parse_args()\n",
    "\n",
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "opt = Object()\n",
    "opt.n_epochs = 1000 # number of epochs of training\n",
    "opt.batch_size = 80 # size of the batches\n",
    "\n",
    "opt.lr = 0.0002\n",
    "\n",
    "# ---------------\n",
    "# Laplacian pyramid\n",
    "opt.laplacian_fsize = 5\n",
    "opt.laplacian_sigma = 1.4\n",
    "opt.n_level = 3 # Laplacian pyramid n_level\n",
    "opt.dis_lrs = [0.0002, 0.0003, 0.001] # adam: learning rate for each discriminator\n",
    "opt.gen_lrs = [0.001, 0.005, 0.01] # adam: learning rate for each generators\n",
    "\n",
    "opt.dis_lrs = [0.0002, 0.0003, 0.0002] # adam: learning rate for each discriminator\n",
    "opt.gen_lrs = [0.001, 0.005, 0.0002] # adam: learning rate for each generators\n",
    "\n",
    "opt.n_update_gen = 1 # update generator parameters every n_update_gen epochs\n",
    "opt.n_update_dis = 1 # update discriminator parameters every n_update_gen epochs\n",
    "# ---------------\n",
    "\n",
    "# ---------------\n",
    "# WGAN GP\n",
    "opt.lambda_gp = 10\n",
    "# ---------------\n",
    "\n",
    "opt.b1 = 0.5 # adam: decay of first order momentum of gradient\n",
    "opt.b2 = 0.999 # adam: decay of first order momentum of gradient\n",
    "opt.n_cpu = 8 # number of cpu threads to use during batch generation\n",
    "opt.latent_dim = 50 # dimensionality of the latent space\n",
    "opt.img_size = 128 # size of each image dimension\n",
    "opt.channels = 3 # number of image channels\n",
    "opt.sample_interval = 100 # interval between image sampling\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCsgX57R-50X"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14MIqAD3wbm3"
   },
   "outputs": [],
   "source": [
    "imgDir = 'emoji'\n",
    "# Configure data loader\n",
    "os.makedirs(imgDir, exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(root=imgDir,\n",
    "      transform=transforms.Compose([\n",
    "          transforms.Resize(opt.img_size),\n",
    "          transforms.CenterCrop(opt.img_size),\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "      ])),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Prepare folder for storing results\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(Tensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    gen_imgs = decoder(z)\n",
    "    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "\n",
    "def upscale_laplacian(data, n_level, batches_done):\n",
    "    d = data[-1]\n",
    "    for i in range(n_level-1):\n",
    "        d1 = F.interpolate(d, scale_factor=2, mode='bilinear')\n",
    "        d = d1 + data[n_level-1-i-1]\n",
    "    save_image(d, \"images/{}-upscale.png\".format(batches_done, j), nrow=5, normalize=True, scale_each=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J9eiYZWSJh38"
   },
   "source": [
    "## Laplacian Pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaTplzoHJlNj"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# this function implementation is intentionally provided\n",
    "#\n",
    "def gaussian_kernel(fsize, sigma):\n",
    "    \"\"\"\n",
    "    Define a Gaussian kernel\n",
    "\n",
    "    Args:\n",
    "        fsize: kernel size\n",
    "        sigma: deviation of the Guassian\n",
    "\n",
    "    Returns:\n",
    "        kernel: (fsize, fsize) Gaussian (normalised) kernel\n",
    "    \"\"\"\n",
    "\n",
    "    _x = _y = (fsize - 1) / 2\n",
    "    x, y = np.mgrid[-_x:_x + 1, -_y:_y + 1]\n",
    "    G = np.exp(-0.5 * (x**2 + y**2) / sigma**2)\n",
    "\n",
    "    return G / G.sum()\n",
    "\n",
    "def generate_laplacian_pyramid(imgs, n_level, fsize, sigma):\n",
    "    pyramid = [None for _ in range(n_level)]\n",
    "\n",
    "    _, c, h, w = imgs.shape\n",
    "\n",
    "    cur = imgs.type(Tensor)\n",
    "    padding = fsize // 2\n",
    "    factor = 2\n",
    "    for i in range(n_level-1):\n",
    "        kernel = Tensor(gaussian_kernel(fsize, sigma).astype('f4')).unsqueeze_(0).repeat((c, 1, 1)).reshape((c, 1, fsize, fsize))\n",
    "        blur = F.conv2d(cur, kernel, groups=c, padding=padding)\n",
    "        p = cur - blur\n",
    "        pyramid[i] = p\n",
    "        cur = cur[:, :, ::factor, ::factor] # downsamplex2\n",
    "    pyramid[n_level-1] = cur\n",
    "    return pyramid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QtS1oxP6LUZ"
   },
   "source": [
    "# GAN架构定义\n",
    "这部分定义了`Generator`和`Discriminator`，代码摘自现有的工程实现。\n",
    "\n",
    "参考[`lapgan.py`](https://github.com/witnessai/LAPGAN/blob/master/mnist/lapgan.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_6F8VRD-tXL"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCuZlEcWQnlo"
   },
   "outputs": [],
   "source": [
    "class LAPGenerator(nn.Module):\n",
    "    def __init__(self, img_size, condd=False):\n",
    "        super(LAPGenerator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.condd = condd\n",
    "\n",
    "        # self.l1, self.conv_blocks = self.conv_blocks1()\n",
    "        self.conv_blocks2()\n",
    "\n",
    "    def forward(self, z, c=None):\n",
    "        out = self.l1(z)\n",
    "        if self.condd:\n",
    "            c = c.reshape(z.shape[0], opt.channels * (self.img_size//2) ** 2)\n",
    "            out2 = self.l2(c)\n",
    "            out = torch.cat((out, out2), 1)\n",
    "            out = self.l3(out)\n",
    "        out = out.view(out.shape[0], self.layer1_depth, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "    def conv_blocks1(self):\n",
    "        # ----------------------\n",
    "        # adjustable parameters\n",
    "        self.init_size = opt.img_size // 4\n",
    "        self.layer1_depth = 512\n",
    "        self.layer2_depth = 256\n",
    "        self.layer3_depth = 128\n",
    "        self.layer4_depth = 64\n",
    "        # ----------------------\n",
    "\n",
    "        l1 = nn.Sequential(nn.Linear(opt.latent_dim, self.layer1_depth * self.init_size ** 2))\n",
    "        # output dim: (self.layer1_depth, self.init_size, self.init_size)\n",
    "        return l1, nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Upsample(scale_factor=2, mode='bicubic'),\n",
    "            nn.LeakyReLU(0.8, inplace=True),\n",
    "            # output dim: (self.layer1_depth, scale_factor * self.init_size, scale_factor * self.init_size)\n",
    "            nn.Conv2d(self.layer1_depth, self.layer2_depth, 3, stride=1, padding=1),\n",
    "            # output dim: (self.layer2_depth, h, w)\n",
    "            # where h=w=(scale_factor * self.init_size)\n",
    "\n",
    "            # Layer 2\n",
    "            nn.BatchNorm2d(self.layer2_depth, 0.8),\n",
    "            nn.LeakyReLU(0.8, inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bicubic'),\n",
    "            # output dim: (self.layer2_depth, 2*h, 2*w)\n",
    "            nn.Conv2d(self.layer2_depth, self.layer3_depth, 3, stride=1, padding=1),\n",
    "            # output dim: (self.layer3_depth, 2*h, 2*w)\n",
    "\n",
    "            # Layer 3\n",
    "            nn.BatchNorm2d(self.layer3_depth, 0.8),\n",
    "            nn.LeakyReLU(0.8, inplace=True),\n",
    "            nn.Conv2d(self.layer3_depth, self.layer4_depth, 3, stride=1, padding=1),\n",
    "            # output dim: (self.layer4_depth, 2*h, 2*w)\n",
    "\n",
    "            # Layer 4\n",
    "            nn.BatchNorm2d(self.layer4_depth, 0.8),\n",
    "            nn.LeakyReLU(0.8, inplace=True),\n",
    "            nn.Conv2d(self.layer4_depth, opt.channels, 3, stride=1, padding=1),\n",
    "            # output dim: (opt.channels, 2*h, 2*w)\n",
    "\n",
    "            # Output Layer\n",
    "            nn.Tanh(),\n",
    "            #nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def conv_blocks2(self):\n",
    "        # ----------------------\n",
    "        # adjustable parameters\n",
    "        self.init_size = self.img_size // 4\n",
    "        self.condition_depth = 1\n",
    "        self.layer1_depth = 128\n",
    "        self.layer2_depth = 64\n",
    "        self.layer3_depth = 256\n",
    "        self.layer4_depth = 128\n",
    "        self.layer5_depth = 64\n",
    "        # ----------------------\n",
    "\n",
    "        # random noise layer\n",
    "        if self.condd:\n",
    "            self.l1 = nn.Sequential(\n",
    "                nn.Linear(opt.latent_dim, self.condition_depth * self.init_size ** 2),\n",
    "                nn.BatchNorm1d(self.condition_depth * self.init_size ** 2, 0.8),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, self.layer1_depth * self.init_size ** 2))\n",
    "        # conditional input layer\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(opt.channels * (self.img_size//2) ** 2, self.condition_depth * (self.img_size//2) ** 2),\n",
    "            nn.BatchNorm1d(self.condition_depth * (self.img_size//2) ** 2, 0.8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # concatenate layer\n",
    "        feature_size = self.condition_depth * self.init_size ** 2\n",
    "        if self.condd:\n",
    "            feature_size += self.condition_depth * (self.img_size//2) ** 2\n",
    "        self.l3 = nn.Sequential(\n",
    "            nn.Linear(feature_size, self.layer1_depth * self.init_size ** 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # output dim: (self.layer1_depth, self.init_size, self.init_size)\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Dropout2d(),\n",
    "            #nn.BatchNorm2d(self.layer1_depth, 0.8),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(self.layer1_depth, self.layer2_depth, 4, stride=2, padding=1),\n",
    "            # output dim: (self.layer2_depth, h, w)\n",
    "            # where h=w=(self.init_size-1)*stride-2*padding+(kernel_size-1)+1\n",
    "\n",
    "            # Layer 2\n",
    "            nn.Dropout2d(),\n",
    "            nn.BatchNorm2d(self.layer2_depth, 0.8),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(self.layer2_depth, self.layer3_depth, 4, stride=2, padding=1, bias=False),\n",
    "            nn.ConvTranspose2d(self.layer2_depth, opt.channels, 4, stride=2, padding=1),\n",
    "            # output dim: (self.layer3_depth, hh, ww)\n",
    "            # where hh=ww=(h-1)*stride-2*padding+(kernel_size-1)+1\n",
    "\n",
    "            # # Layer 3\n",
    "            # nn.Dropout2d(),\n",
    "            # nn.BatchNorm2d(self.layer3_depth, 0.8),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            # #nn.ReLU(),\n",
    "            # nn.Conv2d(self.layer3_depth, self.layer4_depth, 3, stride=1, padding=1, bias=False),\n",
    "            # # output dim: (self.layer4_depth, hh, ww)\n",
    "\n",
    "            # # Layer 4\n",
    "            # nn.Dropout2d(),\n",
    "            # nn.BatchNorm2d(self.layer4_depth, 0.8),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            # #nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(self.layer4_depth, opt.channels, 1, stride=1, padding=0, bias=False),\n",
    "            # # output dim: (opt.channels, hh, ww)\n",
    "\n",
    "            # # Layer 5\n",
    "            # nn.BatchNorm2d(self.layer5_depth, 0.8),\n",
    "            # nn.LeakyReLU(0.2, inplace=True),\n",
    "            # nn.ConvTranspose2d(self.layer5_depth, opt.channels, 1, stride=1, padding=0),\n",
    "            # # output dim: (self.layer5_depth, h, w)\n",
    "\n",
    "            # Output Layer\n",
    "            nn.Tanh(),\n",
    "            #nn.Sigmoid(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwmtLxMy-v1U"
   },
   "source": [
    "## Discriminator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfSGN7PgQuQv"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, condd=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_size = img_size\n",
    "        self.condd = condd\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        in_filters = opt.channels\n",
    "        if self.condd:\n",
    "            in_filters += opt.channels\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_filters, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = self.img_size // 2 ** 4\n",
    "        # print('ds_size: {}'.format(ds_size))\n",
    "        self.adv_layer = nn.Linear(128 * ds_size ** 2, 1)\n",
    "\n",
    "\n",
    "    def forward(self, img, c=None):\n",
    "        # if self.condd:\n",
    "        #     out = torch.cat([out1, out2], 1)\n",
    "        # else:\n",
    "        #     out = img\n",
    "        out = img\n",
    "        out = self.model(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtSfoRA-XeFG"
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.05)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Be1Ly9BQjoxU"
   },
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1V0Lefg0awPy"
   },
   "source": [
    "# Optimizer\n",
    "\n",
    "[example](https://github.com/eriklindernoren/PyTorch-GAN/blob/a163b82beff3d01688d8315a3fd39080400e7c01/implementations/lsgan/lsgan.py#L101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RY6XkqxYH8X"
   },
   "outputs": [],
   "source": [
    "# !!! Minimizes MSE instead of BCE\n",
    "adversarial_loss = [torch.nn.MSELoss() for i in range(opt.n_level)]\n",
    "# adversarial_loss = torch.nn.BCELoss()\n",
    "# adversarial_loss = [torch.nn.BCELoss() for i in range(opt.n_level)]\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = [LAPGenerator(opt.img_size//(2**i), i!=opt.n_level-1).apply(weights_init_normal) for i in range(opt.n_level)]\n",
    "discriminator = [Discriminator(opt.img_size//(2**i), i!=opt.n_level-1).apply(weights_init_normal) for i in range(opt.n_level)]\n",
    "\n",
    "if cuda:\n",
    "    for i in range(opt.n_level):\n",
    "        generator[i].cuda()\n",
    "        discriminator[i].cuda()\n",
    "        adversarial_loss[i].cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8mIfrsbI_oP"
   },
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = [torch.optim.Adam(generator[i].parameters(), lr=opt.gen_lrs[i], betas=(opt.b1, opt.b2)) for i in range(opt.n_level)]\n",
    "optimizer_D = [torch.optim.Adam(discriminator[i].parameters(), lr=opt.dis_lrs[i], betas=(opt.b1, opt.b2)) for i in range(opt.n_level)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3k8Ar5cm8VdC"
   },
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BfjDiSra0O5"
   },
   "source": [
    "# Training\n",
    "\n",
    "[example](https://github.com/eriklindernoren/PyTorch-GAN/blob/a163b82beff3d01688d8315a3fd39080400e7c01/implementations/lsgan/lsgan.py#L142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Laplacian Pyramid\n",
    "            lap_imgs = generate_laplacian_pyramid(imgs, opt.n_level, opt.laplacian_fsize, opt.laplacian_sigma)\n",
    "            gen_imgs = [None for _ in range(opt.n_level)]\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "\n",
    "        for j in range(opt.n_level):\n",
    "        # for j in range(1):\n",
    "        #     j = opt.n_level - 1\n",
    "            real_imgs = Variable(lap_imgs[j].type(Tensor))\n",
    "\n",
    "            # Generate a batch of images\n",
    "            if j < opt.n_level-1:\n",
    "                c = Variable(lap_imgs[j+1].type(Tensor))\n",
    "            else:\n",
    "                c = None\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            optimizer_G[j].zero_grad()\n",
    "\n",
    "            gen_imgs[j] = generator[j](z, c)\n",
    "\n",
    "            # if epoch % 20 == 0:\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            g_loss = adversarial_loss[j](discriminator[j](gen_imgs[j], c), valid)\n",
    "            # g_loss = adversarial_loss[j](1-discriminator[j](gen_imgs[j], c), fake)\n",
    "            # lll = torch.nn.BCELoss()\n",
    "            # g_loss = lll(discriminator[j](gen_imgs[j], c), valid)\n",
    "          \n",
    "          \n",
    "            # fake_validity = discriminator[j](gen_imgs[j], c)\n",
    "            # g_loss = -torch.mean(fake_validity)\n",
    "    \n",
    "            g_loss.backward()\n",
    "            optimizer_G[j].step()\n",
    "    \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "    \n",
    "            optimizer_D[j].zero_grad()\n",
    "\n",
    "            # # Real images\n",
    "            # real_validity = discriminator[j](real_imgs, c)\n",
    "            # # Fake images\n",
    "            # fake_validity = discriminator[j](gen_imgs[j].detach(), c)\n",
    "            # # Gradient penalty\n",
    "            # gradient_penalty = compute_gradient_penalty(discriminator[j], real_imgs.data, gen_imgs[j].data)\n",
    "            # # Adversarial loss\n",
    "            # d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + opt.lambda_gp * gradient_penalty\n",
    "    \n",
    "            # # Measure discriminator's ability to classify real from generated samples\n",
    "            # lll = torch.nn.BCELoss()\n",
    "            # real_loss = lll(discriminator[j](real_imgs, c), valid)\n",
    "            # fake_loss = lll(discriminator[j](gen_imgs[j].detach(), c), fake)\n",
    "            \n",
    "            real_loss = adversarial_loss[j](discriminator[j](real_imgs, c), valid)\n",
    "            fake_loss = adversarial_loss[j](discriminator[j](gen_imgs[j].detach(), c), fake)\n",
    "            d_loss = 0.5 * real_loss + 0.9 * fake_loss\n",
    "    \n",
    "            # adaptive discriminator weight update\n",
    "            # if d_loss.item()/g_loss.item() > 0.1:\n",
    "            d_loss.backward()\n",
    "            optimizer_D[j].step()\n",
    "    \n",
    "            print(\n",
    "                \"[Epoch %d/%d] [nlevel %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                % (epoch+1, opt.n_epochs, j+1, opt.n_level, i+1, len(dataloader), d_loss.item(), g_loss.item())\n",
    "            )\n",
    "\n",
    "        with torch.no_grad():\n",
    "          batches_done = epoch * len(dataloader) + i + 1\n",
    "          if batches_done % opt.sample_interval == 0:\n",
    "              data = [gen_imgs[j].data[:25]]\n",
    "              # data = [real_imgs.data[:25]]\n",
    "              save_image(data[0], \"images/{}-{}.png\".format(batches_done, 2), nrow=5, normalize=True, scale_each=True)\n",
    "              # data = [gen_imgs[j].data[:25] for j in range(opt.n_level)]\n",
    "              # for j in range(opt.n_level):\n",
    "              #     save_image(data[j], \"images/{}-{}.png\".format(batches_done, j), nrow=5, normalize=True, scale_each=True)\n",
    "              #     save_image(real_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "              # upscale_laplacian(data, opt.n_level, batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fesNgdJdhiBo"
   },
   "outputs": [],
   "source": [
    "print(real_imgs.size())\n",
    "print(gen_imgs[j].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gn05coFfxy89"
   },
   "outputs": [],
   "source": [
    "# gen_model_image(LapGan_model, n_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlVR5UQ16FCf"
   },
   "outputs": [],
   "source": [
    "# torch.save(generator,'LAPGAN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tokDGE5uaCBg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYcoz54EfMVP"
   },
   "outputs": [],
   "source": [
    "for j in range(opt.n_level):\n",
    "  print(type(gen_imgs[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVdNu7DVYFh9"
   },
   "outputs": [],
   "source": [
    "data = [gen_imgs[j].data[:25] for j in range(opt.n_level)]\n",
    "upscale_laplacian(data, opt.n_level, batches_done)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LAPGAN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
